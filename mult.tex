\chapter{Multipliers}

To introduce the adopted notation, it is required to compute $p=a \cdot x$ where:
\begin{itemize}
  \item $a=a_{k-1}...a_0$ is the multiplicand.
  \item $x=x_{k-1}...x_0$ is the multiplier.
  \item $p=p_{2k-1}...p_0$ is the product.

\end{itemize}

As a first approach the pen and paper algorithm will be exploited. Using dot notation:
\begin{verbatim}
img32














\end{verbatim}

In this example $k=4$, after the computation of partial products they need to be shifted and summed together. This implies that a multi-operand sum has to be performed with the difference that with respect to the previous case bits are not aligned but they are always shifted.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Parallel-serial approach}
A first idea to implement this algorithm in HW is to use a parallel/sequence approach: in parallel  all partial products are generated and then they are added serially. Both a top-bottom or bottom-up approach are suitable (right shift or left shift).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Right shift approach}
Calling $j$ the number of steps required to accumulate all partial products, it is:

\begin{center}
  \begin{tabular}{|c|c|l|}
    \hline
    j&  Value to be added to acc& Note\\
    \hline
    0&    $a \cdot x_0 \cdot 2^0$&  No shift is required.\\
    1&    $a \cdot x_1 \cdot 2^1$&  It has to be shifted before sum with previous contr.\\
    2&    $a \cdot x_2 \cdot 2^2$&  2 shifts are required to obtain the proper alignment.\\
    ...& ...& ...\\
    \hline
  \end{tabular}
\end{center}

From this approach it comes out that each partial product required a different number of shifts, so a barrel shift should be employed, however since it is a big component with a huge delay we want to avoid it. Let's start from the first partial product and shift all of them by $2^{k-1}$, in this way all contributions have been shifted of the same amount, now when we sum a partial product we shift the value in accumulator of 1 position on the right. In this way we obtain:

\begin{center}
  \begin{tabular}{|c|c|l|}
    \hline
    j&  Value to be added to accumulator& Note\\
    \hline
    0&    $a \cdot x_0 \cdot 2^0$& $a \cdot x_0 \cdot 2^3 =p(0) $ \\
    1&    $a \cdot x_1 \cdot 2^1$& $a \cdot x_1 \cdot 2^3 + (a \cdot x_0 \cdot 2^3) 2^{-1} =p(1) $  \\
    2&    $a \cdot x_2 \cdot 2^2$& $a \cdot x_2 \cdot 2^3 + p(1) 2^{-1} =p(2) $\\
    3&    $a \cdot x_3 \cdot 2^3$& $a \cdot x_3 \cdot 2^3 + p(2) 2^{-1} =p(2) $\\
    \hline
  \end{tabular}
\end{center}

At the end first partial product ($a x_0 2^0$) has been shifted 3 position on the left and 3 position on the right, so it experiences the same amount of shift as in the original algorithm, same thing for the others. With this trick a barrel shifter is no more required.\\

In general we can write that a generic value in the accumulator is equal to:
   $$p(j+1)=p(j)2^{-1}+ax_{j+1} 2^{k-1}$$

From the implementation point of view we will need adder and some shifter.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Left shift approach}
Here we start from MSB contribution:

\begin{center}
  \begin{tabular}{|c|c|l|}
    \hline
    j&  Value to be added to accumulator& Note\\
    \hline
    0&    $a \cdot x_3$& \\
    1&    $a \cdot x_2$& $a \cdot x_3 \cdot 2 + a x_2$  \\
    2&    $a \cdot x_1$& $(a \cdot x_3 \cdot 2 + a x_2) 2 + a x_1$\\
    3&    $a \cdot x_0$& $a x_3 2^3 + a x_2 2^2 + a x_1 2^1+a x_0 2^0$\\
    \hline
  \end{tabular}
\end{center}

In this case we need AND gates, adder and 1 shift left. In general:
$$p(j+1)=p(j)2+ax_{k-j-1}$$

\subsection{Architecture}

\subparagraph{Right shift}

\begin{verbatim}
img33














\end{verbatim}

The product is given by the multiplexer: if $x_j$ is equal to 0 we sum 0, otherwise we take $a$.
The adder output will be on $k+1$ bits which are loaded on p-registers shifting them one position to right. In principle we need a $k$ bit adder (even though the final result will be on $2k$ since we are working only on MSB part). We can improve this architecture since we don't need actual a multiplexer since some gates are enough, moreover we can share $k$ LSB bit of p-reg and $k$ bit x-reg: step by step x-reg shifted one position on the right so at the end it will be empty, instead at the beginning LSB part of p-reg is empty and step step it is populated 1 bit/step towards right. So x-reg and p-reg can share the same register.

\subparagraph{Left shift}
\begin{verbatim}
img34














\end{verbatim}

In principle it is quite similar to the previous one, the difference is that x-reg is a left shift reg and we take the MSB bit as multiplexer selector. Partial products are aligned to the right part of p-reg and we need to sum all bits of p-reg, so this time the adder is a 2k adder having double complexity and delay.\\

For left and right shift approaches the same number of steps is required but in the left one the adder will be slower. Moreover in left approach no sharing between x-reg and p-reg is possible. Two algorithms which are very similar lead to quite different hardware implementation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Unsigned division}
If the product is sequence of sum, division is a sequence of subtractions: in principle the architecture is quite close to the one for the product, provided that the adder can perform subtractions.\\

Taking as a example A=111, B=011 we are required to compute Q and R. Using pen and paper approach:

\begin{verbatim}
div













\end{verbatim}

Obtaining Q=010 and R=0001. In hardware it means that:
\begin{verbatim}
img35










\end{verbatim}
B has to be shifted by 2, by 1 and by 0, since we would need a barrel shift B is never shifted but instead we shift A toward left so the relative alignment between A and B is the correct one. Then if the subtraction is positive the corresponding bit of the quotient has to be set to 1 and the result of subtraction is correct, otherwise the bit in Q has to be put to 0 and the result of subtraction has to be discharged.

Summarizing, for each step k:

\begin{itemize}
  \item Substep 1: shift P and A one bit left.
  \item Substep 2: subtract content of B from P and write result on P.
  \item Substep 3: if result < 0, set LSB of A to 0 and restore previous value of P.
  If result >= 0, set LSB of A to 1.
\end{itemize}

At the end what remains in P is the remainder and in A is the quotient.

\section{Signed multiplication}
Again we want to compute $P=AX$ but one of two input operands may be negative.

\subsection{A<0, X>0}
Recalling:
$$P_{j+1}=(P_j+A X_j 2^k)2^{-1}$$
Perform this left shift means take the MSB (the one containing the sign) and report it as new MSB. This is the only change that has to be performed (update sign extension).

\subparagraph{Example}
Let's assume that $A=10110=(-10)_{10}$ and $X=01011=(11)_{10}$. Then:

\begin{verbatim}
ex























\end{verbatim}

Since the result of the sum is not P(i)1 but 2P(i) we have to perform a right shift and the sign bit extension.

While proceeding in the algorithm the word becomes longer and longer. Since A is negative, all partial products are negative. Our final result consists of 10 bit and converted into decimal it should be equal to -110.

\subsection{A positive, X negative}
Since $X<0$ and it is represented in CA2, we can rewrite it as:
$$X=-X_{k-1}2^{k-1}+\sum_{i=0}^{k-2}x_i2^i$$

meaning that for $0...k-2$ we can perform an addition and update the P register as before but for the last contribution (the one associated to $2^{k-1}$) it has the same weight as the position but since it is negative we have to perform a subtraction. The overall architecture doesn't change a lot provided that the adder is also able to perform subtractions. In the last algorithm step we need to complement the output of multiplexer.

\begin{verbatim}
img36














\end{verbatim}

A drawback of this kind of architecture is that it is iterative. When we have a serial topology and we want to go faster we have to exploit a parallel implementation.

\section{Parallel multipliers}

\subsection{Ripple-carry version}
Many solutions exist, we can perform all the partial sum in only one clock cycle by instantiating many adders and making them work in parallel. If we have to compute P=AX and assuming k=4:
\begin{verbatim}
img37














\end{verbatim}

Each column represents a contribution with a certain weight, meaning that $x_0a_0$ is the only one having the lowest weight, $a_1x_0$ has the same weight of $a_0x_1$ and so on. Weight is equal to the sum of indexes, so we have to place partial products in the correct column. Then we can perform a first level of additions: $a_0x_0$ is alone, for $a_0x_1+a_1x_0$ a half adder is enough, for the others full adders are required. By doing it we obtain that this first level is just a RCA.

\subparagraph{Complexity}
Every row is and adder and $k-1$ level of adders are required. By generalizing this structure we have that $k-1$ RCA are required, $k-2$ rows start with HA and end with FA (\# FA=k-1, \# HA =1) while 1 row starts with HA and end with HA (\# FA=k-2, \# HA =2). Therefore complexity:
$$  \#FA_{tot} = (k-2)(k-1)+k-2$$
$$  \#HA_{tot} = k-2+2$$
Complexity increases quadratically with respect to $k$.

\subparagraph{Critical path}
We can follow the last row of full adder from left to right until reach HA of first level of adder. At every change of row we have to add a delay contribution equal to $T_{sum}$, while when changing column we have to add a delay contribution equal to $T_{carry}$. So we have an amount of row changes equals to the number of rows and an amount of column changes equal to last row length. Total delay is therefore:
$$delay=(k-1)t_{sum}+(k-1+k-2)t_{carry}$$
$$delay=(k-1)t_{sum}+(2k-3)t_{carry}$$

Moreover we assume $t_{sum, HA} \simeq T_{sum, FA}$ and $t_{carry, HA} \simeq T_{carry, FA}$ .

How can we be sure that this is the critical path? If now we start from LSB HA of first row and go down until MSB HA of last rows, we have the same number of row and column changes, meaning that actually there are many critical paths with the same length.

\subsection{Carry save version}
Instead of using RCA we exploit carry save adder for each row:
\begin{verbatim}
img38














\end{verbatim}

It is quite close to previous case although here the carry out is not propagated in the same row but is propagated down to the following stage. As in carry save we compress input data up to two operands and then we sum them together using for instance a RCA, or in general a classic adder.

Also here we can find complexity and critical path delay, a key difference with respect to ripple-carry adder version is that here we have one only critical path (because all the others are shorter).

\subsection{Signed operands in parallel approach - Bough Wooley}
A good approach is to use an array of multipliers called Baugh-Wooley.
starting from the definition of product, assuming that A and B are two operands represented in CA2:

$$A=-a_{n-1}2^{n-1}+\sum_{i=0}^{n-2}a_i2^i$$
$$B=-b_{n-1}2^{n-1}+\sum_{i=0}^{n-2}b_i2^i$$

the product will be:

$$P=AB=+a_{n-1}b_{n-1}2^{2n-2}+ \sum_{i}^{n-2} \sum_{j}^{n-2}a_ib_j2^{i+j}-2^{n-1} \sum_{j=0}^{n-2}a_{n-1}b_j2^j - 2^{n-1} \sum_{i=0}^{n-2}b_{n-1}a_i2^i$$

by calling:

$$-2^{n-1} \sum_{j=0}^{n-2}a_{n-1}b_j2^j \rightarrow X  \qquad x_j=a_{n-1}b_j$$
$$- 2^{n-1} \sum_{i=0}^{n-2}b_{n-1}a_i2^i \rightarrow Y \qquad y_i=b_{n-1}a_i$$

Sign will be in position $2n-1$ (MSB for the product), in position $2n-2$ there will be a contribution coming from $a_{n-1}b_{n-1}2^{2n-2}$. For the double sum, if $i=j=0$ then the associated weight is the one related to column 0, then there are all the others contributions and at the end the maximum index is $(n-2+n-2)=2n-4$.

\begin{verbatim}
eq










\end{verbatim}

Ideally we have all bits already in the correct column, provided that X and Y have a minus in front. Instead of perform a subtraction we take their CA2 and perform an addition.

\begin{verbatim}
eq


















\end{verbatim}
The best way is to write all partial products, combine them properly, sometimes contributions have to be taken as they are, other times they have to be complemented. Finally we need to add +1 in column $n$ and $2n-1$. The overall result is an array organization where 2 kind of cell are required:
\begin{enumerate}
  \item AND + FA.
  \item NAND+ FA: before feeding full adder we have to invert the product result (for X and Y).
\end{enumerate}

The point now is how to allocate these cells.

\begin{verbatim}
example 4 bit














\end{verbatim}

A certain bit of coefficient $a$ is linked to all cells in the same column, so now the weight is no more constant inside a column but along diagonals. So sum bit has same weight of related inputs and it is placed along diagonal, carry out bit instead is propagated along vertical direction.
Using this approach the shape becomes square and regular, otherwise each row should be shifted. White cell means no inversion for the product, gray cell implies NAND on inputs.\\

Finally final adder has to be placed so all sums can be performed, moreover we have to consider the addition +1 in positions $2n-1$ and $n$ for CA2. In fact in last RCA two inputs forced at 1 have been added, actually we could force the first one in a HA in the same diagonal, in this way we substitute a FA having carry in equal to one. The second +1 is in the MSB of the product so it is related to the left most diagonal, which is just the last FA of ripple carry adder. In this way we obtain a regular and modular structure, very suitable for VLSI implementation.

\section{Tree multipliers}
The key idea is the use of a CSA which starting from 3 partial products is able to compress the information providing 2 outputs. Therefore by replicating this structure up to the point for which there are no more partial products a tree is build up and a final adder can be employed to compute the product.
\begin{verbatim}
img40






\end{verbatim}

In general three components are employed, i.e.:
\begin{itemize}
  \item PPM : partial products multiplications.
  \item Tree: made up of CSA.
  \item Final 2-input adder.
\end{itemize}

Many approaches exist to obtain a good multiplier, we will see two of them:
\begin{itemize}
  \item Wallace tree multiplier
  \item Dadda tree multiplier.
\end{itemize}

\subsection{Wallace tree multiplier}
It is based on a very simple idea, first all partial products are computed and then:
\begin{enumerate}
  \item Group three rows of partial products.
  \item Move to the following level of the tree those partial products (dots) which don't belong to any group of step 1.
  \item allocate HAs/FAs in order to add together dots in the identified groups.
\end{enumerate}

\subparagraph{Example}
Assuming $n=5$ and having the list of partial products represented in dots notations:
\begin{verbatim}
img41
















\end{verbatim}

At first level we take the first three rows and some up together bit with the same weight (same column) using FAs and 2 HAs. Then we reply these steps up to the point for which only two rows remain.

\begin{center}
  \begin{tabular}{|l|c|c|}
    \hline
     & FA & HA\\
     \hline
     Level 1&   3&    2\\
     Level 2&   4&    2\\
     Level 3&   3&    3\\
     Final RCA&   4&    2\\
     \hline
     Total&     14&   9\\
     \hline
  \end{tabular}
\end{center}

The number of level in the tree is equal to 3.

\subsection{Dadda tree multiplier}
It is very similar to Wallace tree but it tries to allocate HA/FA as late as possible, in fact we can postpone in time the allocation of a component provided that the number of levels does not increase. Instead in Wallace tree the allocation of resources was made as soon as possible.\\

Firstly some values have to be evaluated, in particular $d_j$ indicates the number of operands to be handled at level j. So in the last level $d_1$ is equal to 2 since in the end we want to have just two rows to be added together with a classic adder, for previous levels it is

$$d_{j+1} = \lfloor 1.5 d_j \rfloor$$

where 1.5 is the compression factor. So it will be: $d_2=3; d_3=4; d_4=6$.\\

At level j we allocate HA/FA in order to achieve in the following level a number of operands not bigger than $d_{j-1}$ meaning that we want to reduce the amount of operands from $d_j$ to $d_{j-1}$. By doing that we also have to consider carry bits since when we allocate a FA we compress from 3 to 1 bit dots in the same column but we also generate a carry out bit which was not present previously.

\subparagraph{Example (the same as before)}

\begin{verbatim}
img42


























\end{verbatim}

since we start from a number of operands equal to 5 we have to take as initial level $d_4=6$ (the integer just up) and as first step we have to reduce from 5 to 4. Every column which has less than 5 elements has to be ignored since we want at the next level no more than 4 rows. It doesn't matter if we can decreases it more, we have to allocate the minimum HW to reach 4 rows by postponing the compression.\\

In first level we start with column number 4 and putting a HA is enough to compress from 5 to 4. Apparently in column 5 there is no need to allocate anything however due to HA in previous column a carry out bit is generated which go in column \#5 and increases its number of bits, this implies that we have to allocate a HA in order to have 4 bit in column \#5. In second level we have to move from 4 bit/column to 3, so we start with 1 HA and then FA. \\

\textit{Issue}: we are decreasing the number of rows at the same rate as in Wallace tree but with much less hardware.

At the end we have the RCA which is more complex than the one in Wallace, in fact here we spend less resources in tree but more in RCA, while in Wallace we have more resources in the tree and the final adder was easier.

 \begin{center}
  \begin{tabular}{|l|c|c|}
    \hline
    & FA & HA\\
    \hline
    Level 4&    0&    2\\
    Level 3&    3&    1\\
    Level 2&    5&    1\\
    Level 1&    8&    0\\
    \hline
    Total&      15&   5\\
    \hline
  \end{tabular}
 \end{center}

Complexity is a little bit lower for Dadda tree, in fact by increasing bits number the difference between Wallace and Dadda increases and Dadda results in cheaper implementation.
In terms of equivalent gates, the following table takes into account not only the tree but also the final RCA.

\begin{center}
  \begin{tabular}{|l|c|c|c|c|}
    \hline
    & Complexity & & Delay &\\
    & Wallace & Dadda& Wallace& Dadda\\
    \hline
    4x4&    104&    104&    21&     19 \\
    8x8&    552&    528&    42&     37 \\
    16x16&    2476&   2336&   77&     69 \\
    32x32&    10283&    9792&   145&    133 \\
    \hline
  \end{tabular}
\end{center}

Both in term of complexity and delay there is some advantages in using Dadda tree. These kind of multipliers can be pipelined, i.e. applying pipeling to CSA performance increases a lot as well as latency.

\section{Booth multiplier}

Starting from binary numbers they can be simplified by using a different representation. For instance if we have to compute  $15 \cdot A$, using a binary representation the coefficient 15 would be expressed uniquely as "001111". Let's suppose to have an internal extended alphabet made up of ${0,1,\overline{1}}$, now to represent 15 many possibilities exist:

\begin{center}
  \begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
     & & & & & & Value & Required operations\\
    \hline
    0&  0&  1&  1&  1&  1&        $P=A+2A+4A+8A$&   3 additions\\
    0&  1&  0&  0&  0&  $\overline{1}$& $P=16A-A$&      1 difference\\
    \hline
  \end{tabular}
\end{center}

The advantages of using this representation allow to reduce a lot complexity in case we want to perform multiplication since it becomes just a series of sums properly shifted. This idea can be exploited to obtain adders based on this algorithm

\subsection{Booth algorithm}
Two consecutive digits are analyzed at the same time, in particular we notice that:
\begin{center}
\begin{tabular}{|c|c|c|c|}
  \hline
  $x_i$&  $x_{i+1}$&  What they represent&  Operation to be performed\\
  \hline
  0&    0&      in middle of sequence&  -\\
  1&    1&      in middle of sequence&  -\\
  1&    0&      Tail of sequence&   $-A \cdot 2^i$\\
  0&    1&      Head of sequence&   $+A \cdot 2^i$\\
  \hline
\end{tabular}
\end{center}
\subparagraph{Example}

Again we start from 15 whose binary representation is "00111". In LSB a dummy zero is inserted to recognize the tail of sequence of ones. We are shifting the window (| |) one position to the left by the time, windows of consecutive steps are overlapping.
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
  \hline
  Step (i)& & & & & & & & Operation to be performed\\
  \hline
    0&    0&    0&  1&  1&  1&  |1& 0|&   $-A$\\
    1&    0&    0&  1&  1&  |1&  1|&  0&    nop\\
    2&    0&    0&  1&  |1&   1|&  1& 0&    nop\\
    3&    0&    0&  |1& 1|&   1&   1& 0&    nop\\
    1&    0&    |0& 1|& 1&    1&   1& 0&    $+A \cdot 2^4$\\
  \hline
\end{tabular}
\end{center}
Since in MSB positions we have only zeros no further operations have to be performed. Actually we can apply this algorithm also to numbers like "0010" resulting in $"01\overline{1}0"$. This is an interactive algorithm, so by looking at more than two-bit at the same time to speed up the executions. This approach leads to radix-4 version whose truth table is the following:
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
  \hline
  $x_{i+1}$&    $x_i$&  $x_{i+1}$&  What they represent& Operation\\
  \hline
  0&        0&    0&      -&          -\\
  0&        0&    1&      head& $+A2^i$\\
  0&        1&    0&      head + tail, sequence of length 1&   $+A2^{i+1}-A2^i=A2^i$\\
  0&        1&    1&      head&  $+A2^{i+1}$\\
  1&        0&    0&      tail&  $-A2^{i+1}$\\
  1&        0&    1&      head + tail&  $-A2^i$\\
  1&        1&    0&      tail&  $-A2^i$\\
  1&        1&    1&      -& -\\
  \hline
\end{tabular}
\end{center}
Applying radix 4 to previous example (always inserting dummy bit in LSB):
\begin{center}
\begin{tabular}{|l|c|c|c|c|c|c|c|c|}
  \hline
  Position&   5&  4&  3&  2&  1&  0&   Operation\\
  \hline
  i=0&    0&  0&  1&  1&  |1& 1&  0|&   $-A2^0$\\
  i=2&    0&  0&  |1& 1&  1|& 1&  0&    $nop$\\
  i=4&    |0&  0& 1|& 1&  1&  1&  0&    $+ A 2^4$\\
  \hline
\end{tabular}
\end{center}
Same result as before but with only 3 steps, so in general using radix-4 we divided by two the number of steps required.
The Booth algorithm can be implement sequentially or in parallel.

\subsection{Sequential approach}

\begin{verbatim}
img43














\end{verbatim}

After multiplex we would need a barrel shift to shift to the left $A, -A, 2A, -2A$ by a value depending on the current step. Since we don't want to use that component we postpone the shift to the accumulator in the opposite directions (right shift). Since it is an iterative algorithm using unrolling we should be able to parallelize it (try to think how to achieve that).

